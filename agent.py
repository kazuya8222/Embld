# -*- coding: utf-8 -*-
import operator
import argparse
from typing import Annotated, Optional, List

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
import os
from pathlib import Path
from dotenv import load_dotenv
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph
from pydantic import BaseModel, Field

# æ—¥æœ¬èªå›ºå®šå‡ºåŠ›ã®æŒ‡ç¤ºï¼ˆå…±é€šã§ä½¿ã†ï¼‰
JP = (
    "ã€é‡è¦ã€‘å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã®ã¿ã§è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚"
    "è‹±èªã¯ä½¿ç”¨ã—ãªã„ï¼ˆå›ºæœ‰åè©ã‚„ã‚µãƒ¼ãƒ“ã‚¹åãªã©å¿…è¦æœ€å°é™ã‚’é™¤ãï¼‰ã€‚"
    "èªå°¾ã‚„ä½“è£ã¯å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ€§æ ¼ã«åˆã‚ã›ã‚‹ã“ã¨ã€‚"
)

# =========================
# 1. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©
# =========================
class Persona(BaseModel):
    name: str = Field(..., description="ãƒšãƒ«ã‚½ãƒŠã®åå‰")
    background: str = Field(..., description="ãƒšãƒ«ã‚½ãƒŠã®æŒã¤èƒŒæ™¯")

class Personas(BaseModel):
    personas: List[Persona] = Field(default_factory=list, description="ãƒšãƒ«ã‚½ãƒŠã®ãƒªã‚¹ãƒˆ")

class Interview(BaseModel):
    persona: Persona = Field(..., description="ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ãƒšãƒ«ã‚½ãƒŠ")
    question: str = Field(..., description="ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§ã®è³ªå•")
    answer: str = Field(..., description="ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§ã®å›ç­”")

class InterviewResult(BaseModel):
    interviews: List[Interview] = Field(default_factory=list, description="ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœã®ãƒªã‚¹ãƒˆ")

class EvaluationResult(BaseModel):
    reason: str = Field(..., description="åˆ¤æ–­ã®ç†ç”±")
    is_sufficient: bool = Field(..., description="æƒ…å ±ãŒååˆ†ã‹ã©ã†ã‹")
    gaps: List[str] = Field(default_factory=list, description="ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±é …ç›®ï¼ˆç®‡æ¡æ›¸ãï¼‰")
    followup_questions: List[str] = Field(default_factory=list, description="ä¸è¶³ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã®å…·ä½“çš„ãªè¿½åŠ å…¥åŠ›è³ªå•")

class ExternalEnvironmentAnalysis(BaseModel):
    customer_analysis: str = Field(..., description="å¸‚å ´ã¨é¡§å®¢ã®åˆ†æ")
    competitor_analysis: str = Field(..., description="ç«¶åˆã®åˆ†æ")
    company_analysis: str = Field(..., description="è‡ªç¤¾(ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)ã®åˆ†æ")
    pest_analysis: str = Field(..., description="ãƒã‚¯ãƒ­ç’°å¢ƒåˆ†æ")
    summary_and_strategy: str = Field(..., description="åˆ†æã®è¦ç´„ã¨æˆ¦ç•¥çš„æè¨€")

# --- æ—§: çµ±åˆè©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆå¾Œæ–¹äº’æ›ã®ãŸã‚æ®‹ç½®ã€‚ä½¿ã‚ãªã„ï¼‰---
class PlanAssessment(BaseModel):
    is_viable: bool = Field(..., description="å€‹äººé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å®Ÿè¡Œå¯èƒ½ã‹ã¤ã€æˆåŠŸã®è¦‹è¾¼ã¿ãŒã‚ã‚‹ã‹")
    reason: str = Field(..., description="ä¸Šè¨˜ã®ã‚ˆã†ã«åˆ¤æ–­ã—ãŸç†ç”±ã®è¦ç´„")
    main_strength: str = Field(..., description="ã“ã®è¨ˆç”»ã®æœ€å¤§ã®å¼·ã¿")
    main_weakness: str = Field(..., description="ã“ã®è¨ˆç”»ã®æœ€å¤§ã®å¼±ç‚¹ãƒ»ãƒªã‚¹ã‚¯")
    recommendation: str = Field(..., description="è©•ä¾¡ã‚’è¸ã¾ãˆã€æ¬¡ã«è¡Œã†ã¹ãã“ã¨ã®ææ¡ˆ")

# --- ãƒšãƒ«ã‚½ãƒŠåˆ¶ç´„ã¨æ¡ç‚¹æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« ---
class PersonaConstraints(BaseModel):
    primary_role: str = Field(..., description="ä¸­å¿ƒã¨ãªã‚‹å½¹å‰²ï¼ˆä¾‹ï¼šå‰¯æ¥­ã®æ•™è‚²ç³»YouTuberï¼‰")
    age_range: Optional[str] = Field(default=None, description="å¹´é½¢å¸¯ï¼ˆä¾‹ï¼š30ä»£å‰åŠãªã©ï¼‰")
    work_style: Optional[str] = Field(default=None, description="åƒãæ–¹/æ™‚é–“åˆ¶ç´„ï¼ˆä¾‹ï¼šæœ¬æ¥­å¤šå¿™ãƒ»å¤œé–“ã®ã¿ãªã©ï¼‰")
    usage_frequency: Optional[str] = Field(default=None, description="åˆ©ç”¨é »åº¦ï¼ˆä¾‹ï¼šé€±1-2å›ï¼‰")
    device_context: Optional[str] = Field(default=None, description="ä¸»ç«¯æœ«/ç’°å¢ƒï¼ˆä¾‹ï¼šPCä¸­å¿ƒ/ãƒ¢ãƒã‚¤ãƒ«ä½µç”¨ãªã©ï¼‰")
    skill_level: Optional[str] = Field(default=None, description="IT/ç·¨é›†ã‚¹ã‚­ãƒ«ã®æ°´æº–")
    must_include_keywords: List[str] = Field(default_factory=list, description="å¿…ãšå«ã‚ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå½¹å‰²/æ–‡è„ˆ/èª²é¡Œï¼‰")
    must_exclude_keywords: List[str] = Field(default_factory=list, description="é™¤å¤–ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¸é©åˆãªå½¹å‰²/æ–‡è„ˆï¼‰")
    notes: Optional[str] = Field(default=None, description="ãã®ä»–ã®åˆ¶ç´„ãƒ»æ³¨æ„ç‚¹")

class PersonaScored(Persona):
    fit_score: float = Field(..., ge=0.0, le=1.0, description="åˆ¶ç´„ã¸ã®é©åˆåº¦ã‚¹ã‚³ã‚¢(0-1)")
    rationale: str = Field(..., description="ã“ã®ãƒšãƒ«ã‚½ãƒŠãŒåˆ¶ç´„ã«é©åˆã™ã‚‹æ ¹æ‹ ï¼ˆæ—¥æœ¬èªï¼‰")

class PersonasScored(BaseModel):
    personas: List[PersonaScored] = Field(default_factory=list, description="æ¡ç‚¹æ¸ˆã¿ãƒšãƒ«ã‚½ãƒŠã®é…åˆ—")

# --- åˆ†å‰²è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ï¼ˆæ–°è¨­ï¼‰ ---
class ProfitabilityAssessment(BaseModel):
    is_profitable: bool = Field(..., description="åç›Šæ€§ã®è¦‹è¾¼ã¿ï¼ˆTrue/Falseï¼‰")
    reason: str = Field(..., description="åç›Šæ€§åˆ¤æ–­ã®ç†ç”±ï¼ˆæ—¥æœ¬èªï¼‰")

class FeasibilityAssessment(BaseModel):
    is_feasible: bool = Field(..., description="å®Ÿç¾å¯èƒ½æ€§ï¼ˆTrue/Falseï¼‰")
    reason: str = Field(..., description="å®Ÿç¾æ€§åˆ¤æ–­ã®ç†ç”±ï¼ˆæ—¥æœ¬èªï¼‰")

class LegalAssessment(BaseModel):
    is_compliant: bool = Field(..., description="æ³•å‹™ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹é©åˆï¼ˆTrue/Falseï¼‰")
    reason: str = Field(..., description="æ³•å‹™åˆ¤æ–­ã®ç†ç”±ï¼ˆæ—¥æœ¬èªï¼šè¦ç´„ãƒ»è‘—ä½œæ¨©ãƒ»å€‹äººæƒ…å ±ãƒ»è¡¨ç¤ºç¾©å‹™ãªã©ï¼‰")

# =========================
# 2. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹(State)
# =========================
class InterviewState(BaseModel):
    initial_problem: str = Field(...)
    initial_persona: str = Field(...)
    initial_solution: str = Field(...)
    clarification_interview_log: str = Field(default="")
    user_request: str = Field(default="")  # ã‚µãƒãƒªãƒ¼
    personas: Annotated[List[Persona], operator.add] = Field(default_factory=list)
    interviews: Annotated[List[Interview], operator.add] = Field(default_factory=list)
    professional_requirements_doc: str = Field(default="", description="ï¼ˆçµ±åˆï¼‰è¦ä»¶å®šç¾©æ›¸ï¼šå€‹äººé–‹ç™ºå‘ã‘ãƒ“ã‚¸ãƒã‚¹ï¼‹é–‹ç™º")
    consultant_analysis_report: Optional[ExternalEnvironmentAnalysis] = Field(default=None, description="å¤–éƒ¨ç’°å¢ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    # æ—§çµ±åˆè©•ä¾¡ã¯ä¿æŒã®ã¿ï¼ˆä½¿ã‚ãªã„ï¼‰
    plan_assessment: Optional[PlanAssessment] = Field(default=None, description="æ—§: åç›Šæ€§ãƒ»å®Ÿç¾æ€§ã®çµ±åˆè©•ä¾¡çµæœ")
    # ååˆ†æ€§è©•ä¾¡ï¼ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã®ï¼‰
    iteration: int = Field(default=0)
    is_information_sufficient: bool = Field(default=False)
    evaluation_result: Optional[EvaluationResult] = Field(default=None)
    followup_round: int = Field(default=0, description="ä¸è¶³æ™‚ã®è¿½åŠ å…¥åŠ›ãƒ©ã‚¦ãƒ³ãƒ‰æ•°ï¼ˆ0ã€œ2ï¼‰")
    pitch_document: str = Field(default="", description="å­¦ç”Ÿå‘ã‘ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸")

    # æ–°: åˆ†å‰²è©•ä¾¡ã®çµæœ
    profitability: Optional[ProfitabilityAssessment] = Field(default=None)
    feasibility: Optional[FeasibilityAssessment] = Field(default=None)
    legal: Optional[LegalAssessment] = Field(default=None)

    # æ”¹å–„ãƒ«ãƒ¼ãƒ—ã®ãŸã‚ã®ãƒ•ãƒ©ã‚°ï¼šæ—¢å­˜ãƒšãƒ«ã‚½ãƒŠã‚’ä¿æŒã—ã¤ã¤è¿½åŠ ç”Ÿæˆã™ã‚‹ã‹
    augment_personas: bool = Field(default=False)

# =========================
# 3. ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
# =========================
class ClarificationInterviewer:
    def __init__(self, llm: ChatOpenAI):
        self.question_generator = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯åˆæœŸå…¥åŠ›ï¼ˆèª²é¡Œãƒ»ãƒšãƒ«ã‚½ãƒŠãƒ»è§£æ±ºç­–ï¼‰ã®è§£é‡ˆã¨å¾Œç¶šã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã®é½Ÿé½¬ã‚’æœ€å°åŒ–ã™ã‚‹ãŸã‚ã®"
                 "ã€æ–¹å‘æ€§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè³ªå•ç¥¨ã€ã‚’ä½œã‚‹å°‚é–€å®¶ã§ã™ã€‚"
                 "ç‰¹å®šã®æ¥­ç•Œãƒ»åª’ä½“ãƒ»UIãƒ»ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆåã«ä¾å­˜ã—ãªã„**æ±ç”¨**ã®è³ªå•ã«ã™ã‚‹ã“ã¨ã€‚"
                 "å…¥åŠ›ï¼ˆèª²é¡Œ/ãƒšãƒ«ã‚½ãƒŠ/è§£æ±ºç­–ï¼‰ã«å«ã¾ã‚Œã‚‹ç”¨èªã‹ã‚‰æ›–æ˜§ã¾ãŸã¯åºƒç¯„ãªèªã‚’æŠ½å‡ºã—ä¸€èˆ¬åŒ–ã—ã¦å®šç¾©ã¥ã‘ã‚’æ±‚ã‚ã‚‹ã€‚"
                 "å›ç­”ã¯çŸ­æ™‚é–“ã§å¯èƒ½ãªã‚ˆã†**é¸æŠä¸­å¿ƒï¼‹æœ€å°é™ã®è‡ªç”±è¨˜å…¥**ã€å¿…è¦ãªã‚‰ã€ã‚ã‹ã‚‰ãªã„ã€ã‚’ç”¨æ„ã™ã‚‹ã€‚"
                 "ã¾ãšAIã®ç†è§£ã‚’2æ–‡ã§è¦ç´„ï¼ˆã‚¨ã‚³ãƒ¼ãƒãƒƒã‚¯ï¼‰â†’åŒæ„/å·®åˆ†â†’ã‚´ãƒ¼ãƒ«/éã‚´ãƒ¼ãƒ«â†’å„ªå…ˆé †ä½â†’å®Œæˆã®å®šç¾©â†’åˆ¶ç´„â†’å…¥å‡ºåŠ›â†’ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–‡è„ˆâ†’æ›–æ˜§èªã®å®šç¾©ã€‚"
                 f"{JP} å‡ºåŠ›ã¯æŒ‡å®šã®Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«**å³å¯†**ã«å¾“ã†ã“ã¨ã€‚"),
                ("human",
                 "ã€å‰æï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆæœŸå…¥åŠ›ï¼‰ã€‘\n"
                 "- èª²é¡Œ: {problem}\n- ãƒšãƒ«ã‚½ãƒŠ: {persona}\n- è§£æ±ºç­–ã®ä»®èª¬: {solution}\n\n"
                 "ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘\n"
                 "# æ–¹å‘æ€§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè³ªå•ç¥¨\n"
                 "## 0. ç§ã®ç†è§£ï¼ˆ2æ–‡ï¼‰\n"
                 "- ï¼ˆAIã®ç†è§£ã‚’2æ–‡ã§è¦ç´„ï¼‰\n"
                 "- ã“ã‚Œã¯ã‚ãªãŸã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã«è¿‘ã„ã§ã™ã‹ï¼Ÿ â†’ ã¯ã„ï¼ã„ã„ãˆ\n"
                 "- ã¡ãŒã†ç‚¹ï¼ˆ1è¡Œï¼‰: ______\n\n"
                 "## 1. ä¸»è¦ã‚´ãƒ¼ãƒ«ï¼ˆæœ€ã‚‚è¿‘ã„1ã¤ï¼‰\n"
                 "- [ ] ä¾¡å€¤æ¤œè¨¼ / [ ] ç²å¾— / [ ] åŠ¹ç‡åŒ– / [ ] æº€è¶³åº¦ / [ ] åç›Š / [ ] ãã®ä»–: ______\n"
                 "- æˆåŠŸã®åˆå›³ï¼ˆ1è¡Œãƒ»æ•°å€¤å¯ï¼‰: ______\n\n"
                 "## 2. ã‚¹ã‚³ãƒ¼ãƒ—ï¼ˆIn / Outï¼‰\n"
                 "- In: 1) ______  2) ______  3) ______\n"
                 "- Out: 1) ______  2) ______  3) ______\n\n"
                 "## 3. å„ªå…ˆé †ä½ï¼ˆå„ãƒšã‚¢ã§ç‰‡æ–¹ã«â—‹ï¼‰\n"
                 "- å“è³ª â—‹ / é€Ÿåº¦ â—‹\n"
                 "- è‡ªå‹•åŒ– â—‹ / æ‰‹å‹•ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« â—‹\n"
                 "- å¹…åºƒã„é©ç”¨ â—‹ / ç‰¹å®šãƒ‹ãƒ¼ã‚ºã«ç‰¹åŒ– â—‹\n"
                 "- åˆæœŸã‚³ã‚¹ãƒˆä½ â—‹ / ç¶­æŒã‚³ã‚¹ãƒˆä½ â—‹\n\n"
                 "## 4. å®Œæˆã®å®šç¾©ï¼ˆ1æ–‡ï¼‰\n"
                 "- ã‚ãªãŸã®å®šç¾©: ______\n\n"
                 "## 5. åˆ¶ç´„ï¼ˆMust / Must-notãƒ»å„æœ€å¤§3ã¤ï¼‰\n"
                 "- Must: 1) ______  2) ______  3) ______\n"
                 "- Must-not: 1) ______  2) ______  3) ______\n\n"
                 "## 6. å…¥åŠ›ã¨å‡ºåŠ›ï¼ˆä¸€èˆ¬åŒ–ï¼‰\n"
                 "- å…¥åŠ›: ãƒ†ã‚­ã‚¹ãƒˆï¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼URLï¼ãƒ•ã‚©ãƒ¼ãƒ ï¼å¤–éƒ¨APIï¼ãã®ä»–: ______\n"
                 "- å‡ºåŠ›: è¦ç´„ï¼å€™è£œä¸€è¦§ï¼åˆ†é¡ï¼ã‚¹ã‚³ã‚¢ï¼ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ï¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ãã®ä»–: ______\n\n"
                 "## 7. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ–‡è„ˆ\n"
                 "- ä¸»ãªåˆ©ç”¨è€…ï¼ˆå½¹å‰²ï¼‰: ______ / åˆ©ç”¨ã‚·ãƒ¼ãƒ³: ______ / é »åº¦: ______\n\n"
                 "## 8. æ›–æ˜§èªã®å…·ä½“åŒ–ï¼ˆæœ€å¤§3ï¼‰\n"
                 "- ç”¨èªA: ______ â†’ æ„å‘³: ______ / åˆ¤æ–­åŸºæº–: ______\n"
                 "- ç”¨èªB: ______ â†’ æ„å‘³: ______ / åˆ¤æ–­åŸºæº–: ______\n"
                 "- ç”¨èªC: ______ â†’ æ„å‘³: ______ / åˆ¤æ–­åŸºæº–: ______\n\n"
                 "## 9. ã‚ªãƒ¼ãƒ—ãƒ³ãªæ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯ï¼ˆæœ€å¤§3ï¼‰\n"
                 "- 1) ______  2) ______  3) ______\n\n"
                 "â€»ã€ã‚ã‹ã‚‰ãªã„ã€ã‚‚å¯ã€‚å›ºæœ‰åã‚„ç‰¹å®šåª’ä½“åã¯é¿ã‘ã€ä¸€èˆ¬åŒ–ã—ãŸè¡¨ç¾ã§ã€‚")
            ])
            | llm
            | StrOutputParser()
        )

    def generate_questions(self, problem: str, persona: str, solution: str) -> str:
        return self.question_generator.invoke({"problem": problem, "persona": persona, "solution": solution})

class RequestSummarizer:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯å„ªç§€ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚åˆæœŸå…¥åŠ›ã¨è³ªç–‘å¿œç­”ãƒ­ã‚°ã‚’èª­ã¿è§£ãã€"
                 "é–‹ç™ºãƒãƒ¼ãƒ ãŒå‚ç…§ã™ã‚‹ãŸã‚ã®ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼ã€ã‚’1æ®µè½ã§ç°¡æ½”ã«ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                 f"{JP}"),
                ("human",
                 "## å…ƒæƒ…å ±\n- **èª²é¡Œ:** {problem}\n- **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒšãƒ«ã‚½ãƒŠ:** {persona}\n- **è§£æ±ºç­–:** {solution}\n\n"
                 "## ãƒ’ã‚¢ãƒªãƒ³ã‚°ãƒ­ã‚°\n{interview_log}\n\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼:")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, problem: str, persona: str, solution: str, interview_log: str) -> str:
        return self.chain.invoke({"problem": problem, "persona": persona, "solution": solution, "interview_log": interview_log})

# æ”¹å–„å¾Œè¦ä»¶å®šç¾©æ›¸ã‹ã‚‰çŸ­ã„ã‚µãƒãƒªãƒ¼ã‚’æŠœãå‡ºã™ï¼ˆæ”¹å–„ãƒ«ãƒ¼ãƒ—ç”¨ï¼‰
class SummaryFromRequirements:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯ç·¨é›†è€…ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¦ä»¶å®šç¾©æ›¸ã‹ã‚‰ã€é–‹ç™ºãƒãƒ¼ãƒ å‘ã‘ã«1æ®µè½ã®è¦ç´„ã‚’ä½œæˆã—ã¾ã™ã€‚"
                 "ãƒˆãƒ¼ãƒ³ã¯ä¸­ç«‹ãƒ»ç°¡æ½”ã€‚å›ºæœ‰åã®ç¾…åˆ—ã‚’é¿ã‘ã€ç›®çš„ãƒ»ä¸»è¦ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤ãƒ»MVPã‚¹ã‚³ãƒ¼ãƒ—ã‚’æ˜ç¤ºã™ã‚‹ã€‚"
                 f"{JP}"),
                ("human", "è¦ä»¶å®šç¾©æ›¸ï¼ˆæŠœç²‹å¯ï¼‰:\n{requirements}\n\n---\n1æ®µè½ã‚µãƒãƒªãƒ¼:")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, requirements: str) -> str:
        return self.chain.invoke({"requirements": requirements})

# --- è¿½åŠ ï¼šåˆ¶ç´„æŠ½å‡ºå™¨ ---
class PersonaConstraintExtractor:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯è¦æ±‚å®šç¾©ã®æ•´åˆæ€§ç›£æŸ»å®˜ã§ã™ã€‚"
                 "åˆæœŸå…¥åŠ›ï¼ˆèª²é¡Œ/ãƒšãƒ«ã‚½ãƒŠ/è§£æ±ºç­–ï¼‰ã¨ãƒ’ã‚¢ãƒªãƒ³ã‚°ãƒ­ã‚°ï¼ˆæ–¹å‘æ€§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè³ªå•ç¥¨ï¼‰ã‹ã‚‰ã€"
                 "ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã«å¿…è¦ãªåˆ¶ç´„ã‚’æ—¥æœ¬èªã§æ§‹é€ åŒ–æŠ½å‡ºã—ã¾ã™ã€‚"
                 f"{JP}"),
                ("human",
                 "## åˆæœŸå…¥åŠ›\n- èª²é¡Œ: {problem}\n- ãƒšãƒ«ã‚½ãƒŠ: {persona}\n- è§£æ±ºç­–: {solution}\n\n"
                 "## ãƒ’ã‚¢ãƒªãƒ³ã‚°ãƒ­ã‚°\n{interview_log}\n\n"
                 "## ã‚¿ã‚¹ã‚¯\n"
                 "- ä¸»è¦ãªå½¹å‰²ãƒ»å¹´é½¢å¸¯ãƒ»ä½¿ç”¨æ–‡è„ˆãƒ»åˆ©ç”¨é »åº¦ãƒ»ã‚¹ã‚­ãƒ«æ°´æº–ãªã©ã®å¿…é ˆæ¡ä»¶ã‚’æŠ½å‡º\n"
                 "- ä¸é©åˆã«ãªã‚Šã‚„ã™ã„å½¹å‰²/æ–‡è„ˆã‚’ç¦æ­¢æ¡ä»¶ã¨ã—ã¦æŠ½å‡º\n"
                 "- å¿…é ˆ/ç¦æ­¢ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚‚ä½œæˆ\n"
                 "- æ¼ã‚ŒãŒã‚ã‚‹å ´åˆã¯ã€åˆæœŸå…¥åŠ›ã¨ãƒ­ã‚°ã‹ã‚‰å¸¸è­˜çš„ã«è£œå®Œ\n")
            ])
            | llm.with_structured_output(PersonaConstraints)
        )

    def run(self, problem: str, persona: str, solution: str, interview_log: str) -> PersonaConstraints:
        return self.chain.invoke({
            "problem": problem,
            "persona": persona,
            "solution": solution,
            "interview_log": interview_log
        })

# --- ç½®æ›ï¼šåˆ¶ç´„æº–æ‹ ï¼‹æ¡ç‚¹ä»˜ããƒšãƒ«ã‚½ãƒŠç”Ÿæˆ ---
class PersonaGeneratorV2:
    def __init__(self, llm: ChatOpenAI, k: int = 10):
        self.gen_llm = llm
        self.k = k
        self.scored_llm = self.gen_llm.with_structured_output(PersonasScored)

    def run(self, user_request: str, constraints: PersonaConstraints) -> Personas:
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã®å°‚é–€å®¶ã§ã™ã€‚"
             "ä»¥ä¸‹ã®**åˆ¶ç´„**ã«é©åˆã™ã‚‹å€™è£œãƒšãƒ«ã‚½ãƒŠã‚’8ã€œ10åä½œæˆã—ã€å„å€™è£œã«å¯¾ã—ã¦"
             "ã€å½¹å‰²é©åˆãƒ»æ–‡è„ˆä¸€è‡´ãƒ»åˆ¶ç´„é †å®ˆãƒ»å·®åˆ¥åŒ–ã€ã‚’ç·åˆã—ãŸé©åˆåº¦ã‚¹ã‚³ã‚¢ï¼ˆ0ã€œ1ï¼‰ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚"
             "äººç‰©å±æ€§ã®é‡è¤‡ã¯é¿ã‘ã‚‹ã“ã¨ã€‚"
             f"{JP} ã™ã¹ã¦æ—¥æœ¬èªã§è¨˜è¿°ã—ã€æ—¥æœ¬åã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚"),
            ("human",
             "## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼\n{user_request}\n\n"
             "## åˆ¶ç´„ï¼ˆå³å®ˆï¼‰\n"
             "- ä¸»è¦å½¹å‰²: {primary_role}\n"
             "- å¹´é½¢å¸¯: {age_range}\n"
             "- åƒãæ–¹/æ™‚é–“åˆ¶ç´„: {work_style}\n"
             "- åˆ©ç”¨é »åº¦: {usage_frequency}\n"
             "- ç«¯æœ«/ç’°å¢ƒ: {device_context}\n"
             "- ã‚¹ã‚­ãƒ«æ°´æº–: {skill_level}\n"
             "- å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {must_include}\n"
             "- ç¦æ­¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {must_exclude}\n"
             "- å‚™è€ƒ: {notes}\n\n"
             "## å‡ºåŠ›è¦ä»¶\n"
             "- 1äººç›®ã¯**ä»£è¡¨ãƒšãƒ«ã‚½ãƒŠ**ï¼ˆæœ€é‡è¦ï¼‰ã¨ã—ã¦ã€åˆ¶ç´„ã¸ã®é©åˆåº¦ãŒæœ€ã‚‚é«˜ã„äººç‰©\n"
             "- å„å€™è£œã« fit_scoreï¼ˆ0ã€œ1ï¼‰ã¨ rationaleï¼ˆ1ã€œ2æ–‡ï¼‰ã‚’ä»˜ä¸\n"
             "- ç¦æ­¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«è©²å½“ã™ã‚‹å½¹å‰²/æ–‡è„ˆã¯**å‡ºã•ãªã„**\n")
        ])

        scored = (prompt | self.scored_llm).invoke({
            "user_request": user_request,
            "primary_role": constraints.primary_role,
            "age_range": constraints.age_range or "æŒ‡å®šãªã—",
            "work_style": constraints.work_style or "æŒ‡å®šãªã—",
            "usage_frequency": constraints.usage_frequency or "æŒ‡å®šãªã—",
            "device_context": constraints.device_context or "æŒ‡å®šãªã—",
            "skill_level": constraints.skill_level or "æŒ‡å®šãªã—",
            "must_include": "ã€".join(constraints.must_include_keywords) if constraints.must_include_keywords else "ï¼ˆãªã—ï¼‰",
            "must_exclude": "ã€".join(constraints.must_exclude_keywords) if constraints.must_exclude_keywords else "ï¼ˆãªã—ï¼‰",
            "notes": constraints.notes or "ï¼ˆãªã—ï¼‰",
        })

        kept = [p for p in scored.personas if p.fit_score >= 0.8]
        kept.sort(key=lambda x: x.fit_score, reverse=True)
        if not kept:
            kept = scored.personas[: self.k]
        else:
            kept = kept[: self.k]

        return Personas(personas=[Persona(name=p.name, background=p.background) for p in kept])

# --- 2å›ç›®ç”¨ï¼ˆã¯ã„/ã„ã„ãˆåŒ–ï¼‰ ---
class YesNoQuestionConverter:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯è³ªå•è¨­è¨ˆã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸè‡ªç”±è¨˜è¿°ã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ç¾¤ã‚’ã€"
                 "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ã¯ã„ï¼ã„ã„ãˆã€ã§ç­”ãˆã‚‰ã‚Œã‚‹å½¢å¼ã«çŸ­æ–‡åŒ–ã—ã¦ãã ã•ã„ã€‚"
                 "å„è³ªå•ã¯1æ–‡ãƒ»æ—¥æœ¬èªãƒ»è‚¯å®šãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä»®èª¬ã«ãªã‚‹ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‹ã€‚"
                 "å¿…è¦ãªã‚‰ï¼ˆä»»æ„ã§ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆå¯ï¼‰ã‚’æœ«å°¾ã«ä»˜ã™ã€‚"
                 f"{JP}"),
                ("human", "è‡ªç”±è¨˜è¿°ã®è³ªå•ç¾¤:\n{questions}\n\nå¤‰æ›å¾Œ: ç®‡æ¡æ›¸ãã§å‡ºåŠ›ã€‚")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, questions: List[str]) -> List[str]:
        raw = self.chain.invoke({"questions": "\n".join(f"- {q}" for q in questions)})
        lines = [l.strip("- ").strip() for l in raw.splitlines() if l.strip()]
        return [l for l in lines if l]

# --- è‡ªå‹•è£œå®Œï¼ˆæœ€çµ‚ãƒ•ã‚§ãƒ¼ã‚ºã®ä»®è¨­å®šï¼‰ ---
class AssumptionBackfiller:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯å€‹äººé–‹ç™ºã®PMã§ã™ã€‚ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼/ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼/ä¸è¶³é …ç›®ã«åŸºã¥ãã€"
                 "ä¸è¶³ã‚’**åˆç†çš„ãªä»®è¨­å®š**ã§è‡ªå‹•è£œå®Œã—ã¾ã™ã€‚"
                 "å„è£œå®Œã¯ã€æ±ºå®šå€¤ï¼ˆ1è¡Œï¼‰ï¼æ ¹æ‹ ï¼ˆ1è¡Œï¼‰ï¼å†ç¢ºèªæ–¹æ³•ï¼ˆ1è¡Œï¼‰ã€ã§çŸ­ãã€‚"
                 "æ—¥æœ¬èªã§ã€ä¿å®ˆçš„ã‹ã¤å®Ÿè£…å¯èƒ½ãªç¾å®Ÿè§£ã‚’å„ªå…ˆã€‚"
                 f"{JP}"),
                ("human",
                 "## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼\n{user_request}\n\n"
                 "## ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ¡ãƒ¢\n{interview_details}\n\n"
                 "## ä¸è¶³é …ç›®\n{gaps}\n\n"
                 "## å‡ºåŠ›\n- é …ç›®å: æ±ºå®šå€¤ / æ ¹æ‹  / å†ç¢ºèªæ–¹æ³•ï¼ˆå„1è¡Œï¼‰ã‚’ç®‡æ¡æ›¸ãã§ã€‚")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, user_request: str, interviews: List[Interview], gaps: List[str]) -> str:
        interview_details = "\n".join(f"- {i.persona.name}: {i.answer}" for i in interviews)
        return self.chain.invoke({
            "user_request": user_request,
            "interview_details": interview_details or "ï¼ˆãªã—ï¼‰",
            "gaps": "\n".join(f"- {g}" for g in gaps) or "ï¼ˆæ˜ç¤ºãªã—ï¼‰"
        })

# --- ãƒ’ã‚¢ãƒªãƒ³ã‚°ï¼ˆå„ãƒšãƒ«ã‚½ãƒŠ3å•ãšã¤ã«å¤‰æ›´ï¼‰ ---
class InterviewConductor:
    def __init__(self, llm: ChatOpenAI, questions_per_persona: int = 3):
        self.llm = llm
        self.k = questions_per_persona

    def run(self, user_request: str, personas: List[Persona]) -> InterviewResult:
        grouped_questions = self._generate_questions(user_request=user_request, personas=personas)
        interviews: List[Interview] = []
        for p, qs in zip(personas, grouped_questions):
            for q in qs:
                a = self._generate_answer(persona=p, question=q)
                interviews.append(Interview(persona=p, question=q, answer=a))
        return InterviewResult(interviews=interviews)

    def _generate_questions(self, user_request: str, personas: List[Persona]) -> List[List[str]]:
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯UXãƒªã‚µãƒ¼ãƒã®è³ªå•è¨­è¨ˆã®å°‚é–€å®¶ã§ã™ã€‚å„ãƒšãƒ«ã‚½ãƒŠã®æ–‡è„ˆã‹ã‚‰ã€"
             "çœŸæ„ã‚’å¼•ãå‡ºã™**å…·ä½“çš„ãªè³ªå•**ã‚’3ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚"
             "å›ç­”ã«æ™‚é–“ãŒã‹ã‹ã‚‰ãªã„ç²’åº¦ã€ã‹ã¤åˆæ„å½¢æˆã«å½¹ç«‹ã¤ã‚‚ã®ã«é™å®šã€‚"
             f"{JP} ç®‡æ¡æ›¸ã3è¡Œã§è¿”ã™ã€‚"),
            ("human",
             "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼:\n{user_request}\n\n"
             "å¯¾è±¡ãƒšãƒ«ã‚½ãƒŠ:\n{persona_name} - {persona_background}\n\n"
             "å‡ºåŠ›: ç®‡æ¡æ›¸ã3å•ã®ã¿")
        ])
        chain = prompt | self.llm | StrOutputParser()
        outs: List[List[str]] = []
        for p in personas:
            raw = chain.invoke({
                "user_request": user_request,
                "persona_name": p.name,
                "persona_background": p.background
            })
            qs = [x.strip("-â€¢ ").strip() for x in raw.splitlines() if x.strip()]
            if len(qs) > self.k:
                qs = qs[: self.k]
            while len(qs) < self.k:
                qs.append("ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹æœ€å¤§ã®æ‡¸å¿µç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿï¼ˆè‡ªç”±è¨˜è¿°ï¼‰")
            outs.append(qs)
        return outs

    def _generate_answer(self, persona: Persona, question: str) -> str:
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯ä»¥ä¸‹ã®ãƒšãƒ«ã‚½ãƒŠã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚"
             "ä¸€äººç§°ã§è‡ªç„¶ãªæ—¥æœ¬èªã€2ã€œ3æ–‡ã€å…·ä½“ä¾‹ã‚’äº¤ãˆã‚‹ã“ã¨ã€‚"
             f"{JP}"),
            ("human", "ãƒšãƒ«ã‚½ãƒŠ: {persona_name} - {persona_background}\nè³ªå•: {question}\nå›ç­”:")
        ])
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({
            "persona_name": persona.name,
            "persona_background": persona.background,
            "question": question
        })

class InformationEvaluator:
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm.with_structured_output(EvaluationResult)

    def run(self, user_request: str, interviews: List[Interview]) -> EvaluationResult:
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯åŒ…æ‹¬çš„ãªè¦ä»¶æ–‡æ›¸ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®æƒ…å ±ã®ååˆ†æ€§ã‚’è©•ä¾¡ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"
             "ä¸è¶³ãŒã‚ã‚‹å ´åˆã¯ã€**ä½•ãŒè¶³ã‚Šãªã„ã‹ï¼ˆgapsï¼‰**ã¨ã€**ãã‚Œã‚’åŸ‹ã‚ã‚‹ãŸã‚ã®è¿½åŠ å…¥åŠ›è³ªå•ï¼ˆfollowup_questionsï¼‰**ã‚’"
             "å…·ä½“çš„ã‹ã¤å®Ÿè¡Œå¯èƒ½ãªå½¢ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
             "è³ªå•ã¯çŸ­æ™‚é–“ã§ç­”ãˆã‚‰ã‚Œã€ã§ãã‚Œã°å®šé‡ãƒ»é¸æŠè‚¢ãƒ»ä¾‹ã‚’å«ã‚ã€å¿…è¦ãªã‚‰ã€ã‚ã‹ã‚‰ãªã„ã€ã‚’è¨±å®¹ã™ã‚‹è¨­è¨ˆã«ã€‚"
             "ãŸã ã—å€‹äººé–‹ç™ºå‰æã«ã¤ãã€è»½å¾®ãªä¸è¶³ã¯**AIã®ä»®è¨­å®šã§è£œå®Œå¯èƒ½**ã¨åˆ¤æ–­ã—ã€"
             "è‡´å‘½çš„ä¸è¶³ã®ã¿ã‚’ã€ä¸ååˆ†ã€ã¨ã™ã‚‹ã€‚è‡´å‘½çš„ä¸è¶³ã®ä¾‹ï¼šæ³•çš„ãƒªã‚¹ã‚¯æœªæ–¹é‡ã€ãƒãƒã‚¿ã‚¤ã‚ºæ–¹é‡ã‚¼ãƒ­ã€ä¸»è¦å…¥å‡ºåŠ›ãŒæœªå®šãªã©ã€‚"
             f"{JP}"),
            ("human",
             "ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼ã¨ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœã«åŸºã¥ãã€ååˆ†æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚\n\n"
             "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼: {user_request}\n\nã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼çµæœ:\n{interview_results}")
        ])
        return (prompt | self.llm).invoke({
            "user_request": user_request,
            "interview_results": "\n".join(
                f"ãƒšãƒ«ã‚½ãƒŠ: {i.persona.name}\nè³ªå•: {i.question}\nå›ç­”: {i.answer}\n" for i in interviews
            )
        })

class FollowupAsker:
    """ä¸è¶³æ™‚ã«ã€EvaluationResult.followup_questions ã‚’å¯¾è©±ã§å–å¾—ã—ã¦ãƒ­ã‚°ã¸è¿½è¨˜"""
    def __init__(self, yesno_converter: Optional[YesNoQuestionConverter] = None):
        self.yesno_converter = yesno_converter

    def collect(self, eval_result: EvaluationResult, mode: str = "free") -> str:
        qs = eval_result.followup_questions or []
        if not qs:
            return ""
        print("\n--- 5b. è¿½åŠ å…¥åŠ›ï¼ˆä¸è¶³æƒ…å ±ã®è§£æ¶ˆï¼‰---")
        print("ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±é …ç›®:")
        for g in eval_result.gaps:
            print(f"- {g}")

        # 2å›ç›®ã¯ã¯ã„/ã„ã„ãˆå½¢å¼ã«å¤‰æ›
        if mode == "yesno" and self.yesno_converter:
            qs = self.yesno_converter.run(qs)
            print("\nï¼ˆä»Šå›ã¯ã€ã¯ã„ï¼ã„ã„ãˆã€ã§ãŠç­”ãˆãã ã•ã„ã€‚å¿…è¦ãªã‚‰ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å¯ï¼‰")

        collected = []
        for idx, q in enumerate(qs, 1):
            print(f"\nQ{idx}: {q}")
            prompt = "å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæœªå®šãªã‚‰ã€ã‚ã‹ã‚‰ãªã„ã€ã§ã‚‚å¯ã€‚Enterã§æ”¹è¡Œã€ç©ºè¡Œã§æ¬¡ã¸ï¼‰:"
            if mode == "yesno":
                prompt = "å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã¯ã„ï¼ã„ã„ãˆã€ä»»æ„ã§ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆã€‚Enterã§æ”¹è¡Œã€ç©ºè¡Œã§æ¬¡ã¸ï¼‰:"
            print(prompt)
            lines = []
            while True:
                try:
                    line = input()
                except EOFError:
                    line = ""
                if not line:
                    break
                lines.append(line)
            ans = "\n".join(lines).strip() or "ï¼ˆç„¡å›ç­”ï¼‰"
            collected.append(f"Q{idx}: {q}\nA{idx}: {ans}")
        header = "## è¿½åŠ å…¥åŠ›ï¼ˆ1å›ç›®ãƒ»è‡ªç”±è¨˜è¿°ï¼‰" if mode == "free" else "## è¿½åŠ å…¥åŠ›ï¼ˆ2å›ç›®ãƒ»ã¯ã„/ã„ã„ãˆï¼‰"
        return header + "\n" + "\n\n".join(collected)

class PitchGenerator:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯ã€æç¤ºã•ã‚ŒãŸæƒ…å ±ã‚’åŸºã«ã€å¤§å­¦ç”Ÿå‘ã‘ã®é­…åŠ›çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸ï¼ˆãƒ”ãƒƒãƒè³‡æ–™ï¼‰ã‚’ä½œæˆã™ã‚‹å­¦ç”Ÿèµ·æ¥­å®¶ã§ã™ã€‚"
                 "å°‚é–€ç”¨èªã‚’é¿ã‘ã€èª­è€…ãŒå…±æ„Ÿã—ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹æ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                 f"{JP} è¦‹å‡ºã—ãƒ»æœ¬æ–‡ã™ã¹ã¦æ—¥æœ¬èªã§è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚"),
                ("human", """ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ã€ä¸€èˆ¬çš„ãªå¤§å­¦ç”ŸãŒè³›åŒã—ã‚„ã™ã„å½¢ã®ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸ã€ã‚’ã€æŒ‡å®šã®Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
## å…¥åŠ›æƒ…å ±
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼:** {user_request}
- **ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è©³ç´° (ãƒšãƒ«ã‚½ãƒŠã”ã¨ã®æ„è¦‹):**
{interview_details}
---
## å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# ğŸš€ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸: [ã“ã“ã«ã‚­ãƒ£ãƒƒãƒãƒ¼ãªã‚¢ãƒ—ãƒªåã‚’è€ƒæ¡ˆã—ã¦å…¥åŠ›]
## ğŸ˜µã€Œã“ã‚“ãªã“ã¨ã§å›°ã£ã¦ãªã„ï¼Ÿã€ - è§£æ±ºã—ãŸã„èª²é¡Œ
> [å­¦ç”Ÿå‘ã‘ã®è¨€è‘‰ã§èª²é¡Œã‚’è¡¨ç¾]
## âœ¨ã€Œã“ã†ãªã£ãŸã‚‰æœ€é«˜ã˜ã‚ƒãªã„ï¼Ÿã€ - åƒ•ãŸã¡ã®è§£æ±ºç­–
> [ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã‚’æ„Ÿæƒ…çš„ã«æå†™]
## ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼
- **ã“ã‚“ãªäººã«ãƒ”ãƒƒã‚¿ãƒª:** [ä¸€è¡Œã§è¡¨ç¾]
## ğŸ› ï¸ ã“ã®ã‚¢ãƒ—ãƒªã§ã§ãã‚‹ã“ã¨ (ä¸»è¦æ©Ÿèƒ½)
- **[ä¸»è¦æ©Ÿèƒ½1]:** [èª¬æ˜]
- **[ä¸»è¦æ©Ÿèƒ½2]:** [èª¬æ˜]
- **[ä¸»è¦æ©Ÿèƒ½3]:** [èª¬æ˜]
## ğŸ’° ãƒ“ã‚¸ãƒã‚¹çš„ãªè©±ï¼ˆã¡ã‚‡ã£ã¨ã ã‘ï¼‰
- [ãƒãƒã‚¿ã‚¤ã‚ºã®æ–¹é‡ï¼ˆä¾‹ï¼šåŸºæœ¬ç„¡æ–™ï¼‹æœ‰æ–™ãƒ—ãƒ©ãƒ³ï¼‰]
## ğŸ¤ ä¸€ç·’ã«ä½œã‚Šã¾ã›ã‚“ã‹ï¼Ÿ
- [å‚åŠ ã‚„å¿œæ´ã®å‘¼ã³ã‹ã‘]""")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, user_request: str, interviews: List[Interview]) -> str:
        return self.chain.invoke({
            "user_request": user_request,
            "interview_details": "\n".join(f"ãƒšãƒ«ã‚½ãƒŠã€Œ{i.persona.name}ã€ã®æ„è¦‹: {i.answer}\n" for i in interviews)
        })

class ProfessionalRequirementsGenerator:
    """çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼šãƒ“ã‚¸ãƒã‚¹ï¼‹é–‹ç™ºï¼‰ã‚’ç”Ÿæˆ"""
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯ã€å€‹äººé–‹ç™ºè€…ãŒå˜ç‹¬ã§ç€æ‰‹ãƒ»é‹ç”¨ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®ã€çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆLeanï¼‹Techï¼‰ã€ã‚’ä½œæˆã™ã‚‹ã€"
                 "çµŒé¨“è±Šå¯Œãªãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…¼ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"
                 "ãƒ“ã‚¸ãƒã‚¹å´ï¼ˆLean BRDï¼‰ã¨é–‹ç™ºå´ï¼ˆTech Specï¼‰ã‚’1ã¤ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«çµ±åˆã—ã€"
                 "ç©ºæ¬„ã‚’ä½œã‚‰ãšä»®èª¬ã§åŸ‹ã‚ã€å®Ÿè¡Œæ‰‹é †ã«è½ã¨ã›ã‚‹ç²’åº¦ã§æ—¥æœ¬èªã®ã¿ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
                 f"{JP} è¡¨ãƒ»ç®‡æ¡æ›¸ããƒ»ç°¡æ˜“è¡¨ã‚’æ´»ç”¨ã—ã€å…·ä½“çš„ã‹ã¤ç°¡æ½”ã«ã€‚"),
                ("human", r"""ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ã€**å€‹äººé–‹ç™ºå‘ã‘**ã®ã€Œçµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆLeanï¼‹Techï¼‰ã€ã‚’ã€æŒ‡å®šã®Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## å…¥åŠ›æƒ…å ±
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼:** {user_request}
- **ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã®è¦ç´„:**
{user_groups_summary}
- **ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è©³ç´°:**
{interview_details}

---
## å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå³å®ˆï¼‰

# ğŸ“ çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼šLeanï¼‹Techï¼‰
## A. ãƒ“ã‚¸ãƒã‚¹ï¼ˆLean BRDï¼‰
### A-1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚«ãƒ¼ãƒ‰
- åç§° / ä¸€è¨€ä¾¡å€¤ / å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ / ã‚¢ãƒ³ãƒã‚´ãƒ¼ãƒ«

### A-2. èª²é¡Œã¨è§£ãç†ç”±ï¼ˆTop3ï¼‰
- ã„ã¾ã®ä»£æ›¿æ‰‹æ®µ / ä¸æº€ç‚¹ / è§£æ±ºã®ä¸€è¨€

### A-3. ä¸»è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¸ãƒ§ãƒ–
- ãƒšãƒ«ã‚½ãƒŠè¦ç´„ / ã‚„ã‚ŠãŸã„ã“ã¨ï¼ˆJobsï¼‰/ åˆ©ç”¨ãƒˆãƒªã‚¬ãƒ¼ãƒ»é »åº¦

### A-4. ä¾¡å€¤ææ¡ˆã¨å·®åˆ¥åŒ–
- æ ¸å¿ƒãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆ / ä»£æ›¿ã¨ã®å·® / æœ€åˆã«å‹ã¦ã‚‹ãƒ‹ãƒƒãƒ

### A-5. åç›Šãƒ¢ãƒ‡ãƒ«ã¨ä¾¡æ ¼ï¼ˆè©¦ç®—ä»˜ãï¼‰
| ãƒ—ãƒ©ãƒ³ | ä¾¡æ ¼ | ä¸»ãªåˆ¶é™/ç‰¹å…¸ | æœŸå¾…CVR | å‚™è€ƒ |
|---|---:|---|---:|---|
- ç„¡æ–™æ ã®ç¯„å›² / æ±ºæ¸ˆæ–¹æ³• / è¿”é‡‘ãƒãƒªã‚·ãƒ¼ï¼ˆç°¡æ˜“ï¼‰

### A-6. ç²å¾—ãƒãƒ£ãƒãƒ«ã¨æœ€åˆã®10äºº
- ãƒãƒ£ãƒãƒ«å€™è£œ / åˆå›æ–½ç­–ï¼ˆ3æœ¬ï¼‰/ ç›®æ¨™KPIï¼ˆæ•°å€¤ï¼‰

### A-7. æˆåŠŸæŒ‡æ¨™ï¼ˆNorth Star & KPIï¼‰
| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æœŸé–“ |
|---|---:|---|

### A-8. ã‚¹ã‚³ãƒ¼ãƒ—ã¨å„ªå…ˆé †ä½ï¼ˆMVPå‰æï¼‰
- In / Out / ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼ˆå“è³ªvsé€Ÿåº¦ç­‰ï¼‰

### A-9. ãƒªã‚¹ã‚¯ãƒ»å‰æãƒ»æ³•å‹™
- ä¸»è¦ãƒªã‚¹ã‚¯ï¼ˆæŠ€è¡“ãƒ»éœ€è¦ãƒ»æ³•å‹™ï¼‰/ è‘—ä½œæ¨©ãƒ»è¦ç´„ã®è¦ç‚¹ / å›é¿ç­–

### A-10. ã‚³ã‚¹ãƒˆè¦‹ç©ã¨ãƒ©ãƒ³ãƒ¬ãƒ¼ãƒˆï¼ˆæ¦‚ç®—ï¼‰
| åŒºåˆ† | åˆæœŸ | æœˆæ¬¡ |
|---|---:|---:|
- æç›Šåˆ†å²ã®ç›®å®‰ï¼ˆå¼ã§ï¼‰

## B. é–‹ç™ºï¼ˆTech Specï¼‰
### B-1. MVPãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ï¼ˆ3ã€œ5ä»¶ï¼‰
- å„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã« **å—ã‘å…¥ã‚ŒåŸºæº–**ï¼ˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼‰

### B-2. ç”»é¢ã¨ä¸»è¦ãƒ•ãƒ­ãƒ¼
- ç”»é¢ä¸€è¦§ / ä¸»ãƒ•ãƒ­ãƒ¼ï¼ˆæ–‡å­—ãƒ¯ã‚¤ãƒ¤ã§OKï¼‰/ çŠ¶æ…‹é·ç§»ã®è¦ç‚¹

### B-3. ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆç°¡æ˜“ERï¼‰
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ / ä¸»å±æ€§ / é–¢ä¿‚ / ä¿æŒæœŸé–“ãƒ»å‰Šé™¤æ–¹é‡

### B-4. API / å¤–éƒ¨é€£æº
- å¿…è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆå…¥å‡ºåŠ›ãƒ»ã‚¨ãƒ©ãƒ¼ã®åŸºæœ¬å½¢ï¼‰/ å¸¯åŸŸãƒ»åˆ¶é™ã®ç›®å®‰

### B-5. éæ©Ÿèƒ½è¦ä»¶ï¼ˆå€‹äººé–‹ç™ºç¾å®Ÿè§£ï¼‰
- æ€§èƒ½ï¼ˆç›®å®‰ï¼‰/ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ / å¯ç”¨æ€§ / ç›£è¦–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

### B-6. é‹ç”¨ãƒ»ã‚µãƒãƒ¼ãƒˆ
- é‹ç”¨æ‰‹é †ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»éšœå®³å¯¾å¿œï¼‰/ è¨ˆæ¸¬ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ / æ—¢çŸ¥ã®åˆ¶ç´„

### B-7. é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆ12é€±ç›®å®‰ï¼‰
- W0-2 / W3-6 / W7-12 ã¨ **ã‚«ãƒƒãƒˆåŸºæº–**

### B-8. ç”¨èªé›†ï¼ˆæ›–æ˜§èªã®å®šç¾©ï¼‰
- ç”¨èªA/B/Cï¼ˆ1è¡Œã®æ„å‘³ï¼‹åˆ¤æ–­åŸºæº–ï¼‰
""")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, user_request: str, interviews: List[Interview]) -> str:
        user_groups_summary = "\n".join(
            f"- **(ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ— {chr(65 + i)}):** {interview.persona.background}"
            for i, interview in enumerate(interviews)
        )
        return self.chain.invoke({
            "user_request": user_request,
            "user_groups_summary": user_groups_summary,
            "interview_details": "\n".join(
                f"ãƒšãƒ«ã‚½ãƒŠ: {i.persona.name}\nè³ªå•: {i.question}\nå›ç­”: {i.answer}\n" for i in interviews
            )
        })

class ConsultantExternalAnalyzer:
    def __init__(self, llm: ChatOpenAI):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯å¤–è³‡ç³»æˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã®ã‚·ãƒ‹ã‚¢ã€‚å€‹äººé–‹ç™ºã®å®Ÿè¡Œå¯å¦åˆ¤æ–­ã«è¶³ã‚‹ç²¾åº¦ã§å¤–éƒ¨ç’°å¢ƒã‚’åˆ†æã™ã‚‹ã€‚"
             "3C/PESTã«åŠ ãˆã€JTBDãƒ»å¸‚å ´è¦æ¨¡æ¨å®šï¼ˆTAM/SAM/SOMï¼‰ãƒ»ãƒãƒ¼ã‚¿ãƒ¼ã®5ãƒ•ã‚©ãƒ¼ã‚¹ãƒ»è¦åˆ¶/è¦ç´„ãƒãƒƒãƒ—ãƒ»"
             "GTMï¼ˆç²å¾—å®Ÿé¨“ï¼‰ãƒ»ãƒ¦ãƒ‹ãƒƒãƒˆã‚¨ã‚³ãƒãƒŸã‚¯ã‚¹ï¼ˆCAC/LTV/ç²—åˆ©/å›åæœˆï¼‰ãƒ»æŠ€è¡“å®Ÿç¾æ€§ï¼ˆæ¨è«–ã‚³ã‚¹ãƒˆ/é…å»¶ï¼‰ãƒ»"
             "å·®åˆ¥åŒ–/ãƒ¢ãƒ¼ãƒˆãƒ»ä¸»è¦ãƒªã‚¹ã‚¯ï¼†å¯¾ç­–ãƒ»ã‚·ãƒŠãƒªã‚ªï¼ˆæ¥½è¦³/ä¸­ä½/æ‚²è¦³ï¼‰ã‚’å«ã‚ã€"
             "ä¸è¶³æƒ…å ±ã¯**æ˜ç¤ºçš„ãªä»®å®š**ã§è£œå®Œã—ã€æ•°å€¤ã¯**ãƒ¬ãƒ³ã‚¸**ã¨**ç®—å‡ºå¼**ã‚’ç¤ºã™ã€‚"
             "å‡ºåŠ›ã¯æ—¥æœ¬èªã€Markdownã§ç°¡æ½”ã«ã€‚"
             "ä»¥ä¸‹ã®5ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆcustomer_analysis/competitor_analysis/company_analysis/pest_analysis/summary_and_strategyï¼‰"
             "ã«ã€ãã‚Œãã‚Œé–¢é€£ã™ã‚‹æ·±æ˜ã‚Šè¦ç´ ã‚’**å†…åŒ…**ã—ã¦è¨˜è¿°ã›ã‚ˆã€‚"
             f"{JP}"),
            ("human", """ä»¥ä¸‹ã®çµ±åˆè¦ä»¶å®šç¾©æ›¸ã‚’ã‚‚ã¨ã«ã€å¤–éƒ¨ç’°å¢ƒã‚’ç²¾ç·»ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

## å‚è€ƒè³‡æ–™
- **çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼‰:** {professional_requirements_doc}

## å‡ºåŠ›ä»•æ§˜ï¼ˆ5ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æ·±æ˜ã‚Šè¦ç´ ã‚’å†…åŒ…ã—ã¦è¿”ã™ï¼‰
- customer_analysis: 
  - ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆJTBD/ãƒ‹ãƒ¼ã‚º/åˆ©ç”¨ãƒˆãƒªã‚¬ãƒ¼/ä»£æ›¿æ‰‹æ®µï¼‰
  - å¸‚å ´è¦æ¨¡æ¨å®šï¼ˆTAM/SAM/SOMï¼‰ï¼šä»®å®šä¸€è¦§ã€ç®—å‡ºå¼ã€ãƒ¬ãƒ³ã‚¸ã‚’Markdownè¡¨ã§
  - åˆæœŸãƒ‹ãƒƒãƒï¼ˆãƒ“ãƒ¼ãƒãƒ˜ãƒƒãƒ‰ï¼‰ã¨â€œé¸ã°ã‚Œã‚‹ç†ç”±â€
- competitor_analysis:
  - ç›´æ¥/é–“æ¥ç«¶åˆã®åœ°å›³ï¼ˆã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
  - æ©Ÿèƒ½Ã—ä¾¡æ ¼ã®æ¯”è¼ƒè¡¨ï¼ˆæœ€å°é™ã®åˆ—ï¼šä¾¡æ ¼å¸¯/ä¸»è¦æ©Ÿèƒ½/é•·æ‰€/çŸ­æ‰€ï¼‰
  - ãƒãƒ¼ã‚¿ãƒ¼ã®5ãƒ•ã‚©ãƒ¼ã‚¹è¦ç´„ï¼ˆ1ã€œ2è¡ŒÃ—5é …ç›®ï¼‰
  - å‚å…¥éšœå£ã¨æ¨¡å€£å¯èƒ½æ€§
- company_analysis:
  - ã‚³ã‚¢å·®åˆ¥åŒ–/ãƒ¢ãƒ¼ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿/ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼/ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç­‰ï¼‰
  - æŠ€è¡“å®Ÿç¾æ€§ï¼šæ¨è«–é…å»¶ç›®å®‰ã€1å‡¦ç†ã‚ãŸã‚Šæ¦‚ç®—ã‚³ã‚¹ãƒˆï¼ˆç®—å‡ºå¼ï¼‰
  - ãƒ¦ãƒ‹ãƒƒãƒˆã‚¨ã‚³ãƒãƒŸã‚¯ã‚¹ï¼ˆARPU/CAC/ç²—åˆ©/å›åæœˆï¼‰ï¼šä»®å®šã¨å¼ã‚’è¡¨ã§
  - GTMï¼šæœ€åˆã®10äººæ–½ç­–ã€ä¸»è¦ãƒãƒ£ãƒãƒ«ã€åˆæœŸKPI
- pest_analysis:
  - P/E/S/T å„2ã€œ3ç‚¹ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼‹**å«æ„ï¼ˆImplicationï¼‰**ã‚’ä½µè¨˜
  - è¦åˆ¶/è¦ç´„ãƒãƒƒãƒ—ï¼ˆè‘—ä½œæ¨©/ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ToS/ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼/è¡¨ç¤ºç¾©å‹™ï¼‰
- summary_and_strategy:
  - æˆ¦ç•¥éª¨å­ï¼ˆå‹ã¡ç­‹ã€æ¨ã¦ã‚‹ã‚‚ã®ã€MVPã®æœ€å°å‹åˆ©æ¡ä»¶ï¼‰
  - ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ï¼ˆ0-4é€±/5-8é€±/9-12é€±ï¼‰ã¨è¨ˆæ¸¬æŒ‡æ¨™
  - ãƒªã‚¹ã‚¯Ã—å¯¾ç­–ï¼ˆTop5ã€å›é¿/ä½æ¸›/å—å®¹ã®åˆ¥ï¼‰
  - ã‚·ãƒŠãƒªã‚ªåˆ†æï¼ˆæ¥½è¦³/ä¸­ä½/æ‚²è¦³ï¼šç²å¾—é€Ÿåº¦ã€åç›Šæ€§ã€ä¸»è¦å‰æï¼‰
""")
        ])
        self.chain = prompt | llm.with_structured_output(ExternalEnvironmentAnalysis)

    def run(self, professional_requirements_doc: str) -> ExternalEnvironmentAnalysis:
        return self.chain.invoke({"professional_requirements_doc": professional_requirements_doc})

# ====== åˆ†å‰²ã‚¢ã‚»ãƒƒã‚µ ======
class ProfitabilityAssessor:
    def __init__(self, llm: ChatOpenAI):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯åç›Šæ€§ã®ç›£æŸ»å®˜ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¦ä»¶å®šç¾©æ›¸ã¨å¤–éƒ¨ç’°å¢ƒåˆ†æã‹ã‚‰ã€"
             "å€‹äººé–‹ç™ºãŒ**ç¶™ç¶šçš„ã«é»’å­—åŒ–**ã§ãã‚‹è¦‹è¾¼ã¿ãŒã‚ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"
             "ä¾¡æ ¼æˆ¦ç•¥ã€ARPUã€CACã€ç²—åˆ©ã€å›åæœŸé–“ã€ãƒãƒ£ãƒ¼ãƒ³ã€ãƒãƒ£ãƒãƒ«ã®ç¾å®Ÿæ€§ã‚’çŸ­ãåŸå‘³ã€‚"
             f"{JP} å‡ºåŠ›ã¯æ§‹é€ åŒ–ï¼ˆis_profitable, reasonï¼‰ã€‚"),
            ("human",
             "## è¦ä»¶å®šç¾©æ›¸\n{requirements}\n\n## å¤–éƒ¨ç’°å¢ƒ\né¡§å®¢:{cust}\nç«¶åˆ:{comp}\nè‡ªç¤¾:{compy}\nPEST:{pest}\nè¦ç´„:{sumst}\n\nåˆ¤å®š:")
        ])
        self.chain = prompt | llm.with_structured_output(ProfitabilityAssessment)

    def run(self, req: str, ext: ExternalEnvironmentAnalysis) -> ProfitabilityAssessment:
        return self.chain.invoke({
            "requirements": req,
            "cust": ext.customer_analysis,
            "comp": ext.competitor_analysis,
            "compy": ext.company_analysis,
            "pest": ext.pest_analysis,
            "sumst": ext.summary_and_strategy,
        })

class FeasibilityAssessor:
    def __init__(self, llm: ChatOpenAI):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯å®Ÿç¾å¯èƒ½æ€§ã®ç›£æŸ»å®˜ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¦ä»¶å®šç¾©æ›¸ã¨å¤–éƒ¨ç’°å¢ƒåˆ†æã‹ã‚‰ã€"
             "å€‹äººãŒè² å‚µãªã**ç¾å®Ÿçš„ãªå·¥æ•°ãƒ»ã‚³ã‚¹ãƒˆãƒ»æŠ€è¡“é›£æ˜“åº¦**ã§å®Ÿè£…ãƒ»é‹ç”¨ã§ãã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"
             "MVPã®ç¯„å›²ã€ã‚¹ã‚­ãƒ«å‰æã€æ¨è«–ã‚³ã‚¹ãƒˆ/é…å»¶ã€é‹ç”¨è² è·ã€ä¾å­˜å¤–éƒ¨APIã®åˆ¶ç´„ãªã©ã‚’ç°¡æ½”ã«è©•ä¾¡ã€‚"
             f"{JP} å‡ºåŠ›ã¯æ§‹é€ åŒ–ï¼ˆis_feasible, reasonï¼‰ã€‚"),
            ("human",
             "## è¦ä»¶å®šç¾©æ›¸\n{requirements}\n\n## å¤–éƒ¨ç’°å¢ƒ\né¡§å®¢:{cust}\nç«¶åˆ:{comp}\nè‡ªç¤¾:{compy}\nPEST:{pest}\nè¦ç´„:{sumst}\n\nåˆ¤å®š:")
        ])
        self.chain = prompt | llm.with_structured_output(FeasibilityAssessment)

    def run(self, req: str, ext: ExternalEnvironmentAnalysis) -> FeasibilityAssessment:
        return self.chain.invoke({
            "requirements": req,
            "cust": ext.customer_analysis,
            "comp": ext.competitor_analysis,
            "compy": ext.company_analysis,
            "pest": ext.pest_analysis,
            "sumst": ext.summary_and_strategy,
        })

class LegalAssessor:
    def __init__(self, llm: ChatOpenAI):
        prompt = ChatPromptTemplate.from_messages([
            ("system",
             "ã‚ãªãŸã¯æ³•å‹™ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç›£æŸ»å®˜ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¦ä»¶å®šç¾©æ›¸ã¨å¤–éƒ¨ç’°å¢ƒåˆ†æã‹ã‚‰ã€"
             "è‘—ä½œæ¨©ãƒ»å•†æ¨™ãƒ»ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ è¦ç´„ãƒ»å€‹äººæƒ…å ±/ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ»è¡¨ç¤ºç¾©å‹™ãƒ»å¹´é½¢åˆ¶é™ãªã©ã®è¦³ç‚¹ã§"
             "ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãŒ**é©åˆ**ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚é‡å¤§é•åã®æã‚ŒãŒã‚ã‚Œã°Falseã€‚"
             f"{JP} å‡ºåŠ›ã¯æ§‹é€ åŒ–ï¼ˆis_compliant, reasonï¼‰ã€‚"),
            ("human",
             "## è¦ä»¶å®šç¾©æ›¸\n{requirements}\n\n## å¤–éƒ¨ç’°å¢ƒ\né¡§å®¢:{cust}\nç«¶åˆ:{comp}\nè‡ªç¤¾:{compy}\nPEST:{pest}\nè¦ç´„:{sumst}\n\nåˆ¤å®š:")
        ])
        self.chain = prompt | llm.with_structured_output(LegalAssessment)

    def run(self, req: str, ext: ExternalEnvironmentAnalysis) -> LegalAssessment:
        return self.chain.invoke({
            "requirements": req,
            "cust": ext.customer_analysis,
            "comp": ext.competitor_analysis,
            "compy": ext.company_analysis,
            "pest": ext.pest_analysis,
            "sumst": ext.summary_and_strategy,
        })

# ====== æ”¹å–„å™¨ ======
class RequirementsImprover:
    def __init__(self, llm: ChatOpenAI):
        self.chain = (
            ChatPromptTemplate.from_messages([
                ("system",
                 "ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢PMã§ã™ã€‚ä»¥ä¸‹ã®ææ–™ï¼ˆè¦ä»¶å®šç¾©æ›¸ã€å¤–éƒ¨ç’°å¢ƒã€è©•ä¾¡ã®NGç†ç”±ï¼‰ã‚’å—ã‘ã€"
                 "å€‹äººé–‹ç™ºã§ç¾å®Ÿçš„ã«å‹ã¦ã‚‹å½¢ã¸**è¦ä»¶å®šç¾©æ›¸ã‚’æ”¹è¨‚**ã—ã¾ã™ã€‚"
                 "æ”¹è¨‚æ–¹é‡ï¼šMVPã®çµã‚Šè¾¼ã¿ãƒ»å·®åˆ¥åŒ–ã®æ˜ç¢ºåŒ–ãƒ»åç›Šæ€§ã®æ”¹å–„ï¼ˆä¾¡æ ¼/ã‚³ã‚¹ãƒˆ/ãƒãƒ£ãƒãƒ«ï¼‰ãƒ»"
                 "å®Ÿç¾æ€§ã®å‘ä¸Šï¼ˆæ®µéšå°å…¥/å‰Šæ¸›/ä»£æ›¿æ‰‹æ®µï¼‰ãƒ»æ³•å‹™ã®é©åˆï¼ˆãƒ•ãƒ­ãƒ¼/åŒæ„/è¡¨è¨˜/æ¨©åˆ©ï¼‰ã®ã„ãšã‚Œã‹ã€‚"
                 "å…ƒã®è‰¯ã•ã¯ä¿æŒã—ã¤ã¤ã€å±é™ºãªä»®å®šã¯æ˜ç¢ºã«å¤‰æ›´ã€‚"
                 f"{JP} Markdownã§å®Œçµãªæ”¹è¨‚ç‰ˆã‚’è¿”ã™ã€‚"),
                ("human",
                 "## æ—§ è¦ä»¶å®šç¾©æ›¸\n{req}\n\n## å¤–éƒ¨ç’°å¢ƒã®è¦ç‚¹\n- é¡§å®¢:{cust}\n- ç«¶åˆ:{comp}\n- è‡ªç¤¾:{compy}\n- PEST:{pest}\n- è¦ç´„:{sumst}\n\n"
                 "## è©•ä¾¡NGç†ç”±ï¼ˆåç›Šæ€§/å®Ÿç¾æ€§/æ³•å‹™ã®ã„ãšã‚Œã‹ï¼‰\n{bad_reasons}\n\n"
                 "## å‡ºåŠ›: æ”¹è¨‚ç‰ˆã®è¦ä»¶å®šç¾©æ›¸ï¼ˆMarkdownï¼‰")
            ])
            | llm
            | StrOutputParser()
        )

    def run(self, req: str, ext: ExternalEnvironmentAnalysis, bad_reasons: List[str]) -> str:
        return self.chain.invoke({
            "req": req,
            "cust": ext.customer_analysis,
            "comp": ext.competitor_analysis,
            "compy": ext.company_analysis,
            "pest": ext.pest_analysis,
            "sumst": ext.summary_and_strategy,
            "bad_reasons": "\n".join(f"- {r}" for r in bad_reasons) if bad_reasons else "ï¼ˆæ˜ç¤ºãªã—ï¼‰"
        })

# =========================
# 4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# =========================
class RequirementsAgent:
    def __init__(self, llm: ChatOpenAI, persona_k: int = 5):
        self.clarification_interviewer = ClarificationInterviewer(llm=llm)
        self.request_summarizer = RequestSummarizer(llm=llm)
        self.summary_from_requirements = SummaryFromRequirements(llm=llm)

        # åˆ¶ç´„æŠ½å‡ºï¼‹åˆ¶ç´„æº–æ‹ ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ
        self.constraint_extractor = PersonaConstraintExtractor(llm=llm)
        self.persona_generator = PersonaGeneratorV2(llm=llm, k=persona_k)

        # 2å›ç›®ç”¨ã®ã¯ã„/ã„ã„ãˆå¤‰æ›å™¨
        self.yesno_converter = YesNoQuestionConverter(llm=llm)

        self.interview_conductor = InterviewConductor(llm=llm, questions_per_persona=3)
        self.information_evaluator = InformationEvaluator(llm=llm)
        self.assumption_backfiller = AssumptionBackfiller(llm=llm)
        self.followup_asker = FollowupAsker(yesno_converter=self.yesno_converter)
        self.professional_requirements_generator = ProfessionalRequirementsGenerator(llm=llm)
        self.consultant_analyzer = ConsultantExternalAnalyzer(llm=llm)

        # æ–°ãƒ»åˆ†å‰²ã‚¢ã‚»ãƒƒã‚µ
        self.profitability_assessor = ProfitabilityAssessor(llm=llm)
        self.feasibility_assessor = FeasibilityAssessor(llm=llm)
        self.legal_assessor = LegalAssessor(llm=llm)

        # æ”¹å–„å™¨
        self.requirements_improver = RequirementsImprover(llm=llm)

        # æ—§ï¼šPlanAssessorï¼ˆä½¿ã‚ãªã„ãŒå°å­—ã®ãŸã‚æ®‹ã›ã‚‹ï¼‰
        self.plan_assessor = None

        self.app = self._build_graph()

    def _build_graph(self):
        workflow = StateGraph(InterviewState)

        # --- ãƒãƒ¼ãƒ‰ ---
        workflow.add_node("clarification_interview", self._clarification_interview_node)
        workflow.add_node("summarize_request", self._summarize_request_node)
        workflow.add_node("generate_personas", self._generate_personas_node)
        workflow.add_node("conduct_interviews", self._conduct_interviews_node)
        workflow.add_node("evaluate_information", self._evaluate_information_node)
        workflow.add_node("ask_followups", self._ask_followups_node)
        workflow.add_node("generate_professional_requirements", self._generate_professional_requirements_node)
        workflow.add_node("analyze_environment", self._analyze_environment_node)

        # æ–°ï¼šåˆ†å‰²è©•ä¾¡ã¨ã‚²ãƒ¼ãƒˆ
        workflow.add_node("assess_profitability", self._assess_profitability_node)
        workflow.add_node("assess_feasibility", self._assess_feasibility_node)
        workflow.add_node("assess_legal", self._assess_legal_node)
        workflow.add_node("assessment_gate", self._assessment_gate_node)

        # æ”¹å–„ãƒ«ãƒ¼ãƒ—
        workflow.add_node("improve_requirements", self._improve_requirements_node)

        # æœ€çµ‚æˆæœç‰©
        workflow.add_node("generate_pitch", self._generate_pitch_node)

        # --- ã‚¨ãƒƒã‚¸ ---
        workflow.set_entry_point("clarification_interview")
        workflow.add_edge("clarification_interview", "summarize_request")
        workflow.add_edge("summarize_request", "generate_personas")
        workflow.add_edge("generate_personas", "conduct_interviews")
        workflow.add_edge("conduct_interviews", "evaluate_information")

        # åˆ†å²: ä¸ååˆ†ãªã‚‰ 1å›ç›®=è‡ªç”±è¨˜è¿° / 2å›ç›®=ã¯ã„ãƒ»ã„ã„ãˆ / 3å›ç›®ä»¥é™=è‡ªå‹•è£œå®Œâ†’å‰é€²
        workflow.add_conditional_edges(
            "evaluate_information",
            self._after_evaluation_branch,
            {
                "enough": "generate_professional_requirements",
                "need_followups": "ask_followups",
                "autofill_and_forward": "generate_professional_requirements",
            },
        )

        # è¿½åŠ å…¥åŠ›å¾Œã¯å†è¦ç´„ â†’ å†åº¦ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰
        workflow.add_edge("ask_followups", "summarize_request")

        # è¦ä»¶å®šç¾©æ›¸ â†’ å¤–éƒ¨ç’°å¢ƒ â†’ åˆ†å‰²è©•ä¾¡ï¼ˆåç›Šæ€§â†’å®Ÿç¾æ€§â†’æ³•å‹™ï¼‰ â†’ ã‚²ãƒ¼ãƒˆ
        workflow.add_edge("generate_professional_requirements", "analyze_environment")
        workflow.add_edge("analyze_environment", "assess_profitability")
        workflow.add_edge("assess_profitability", "assess_feasibility")
        workflow.add_edge("assess_feasibility", "assess_legal")
        workflow.add_edge("assess_legal", "assessment_gate")

        # ã‚²ãƒ¼ãƒˆï¼šå…¨Trueãªã‚‰æœ€çµ‚æˆæœç‰©ã€Falseå«ã‚€ãªã‚‰æ”¹å–„ãƒ«ãƒ¼ãƒ—
        workflow.add_conditional_edges(
            "assessment_gate",
            self._assessment_gate_branch,
            {
                "all_true": "generate_pitch",
                "refine_loop": "improve_requirements",
            },
        )

        # æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼šæ”¹è¨‚è¦ä»¶å®šç¾©æ›¸â†’ï¼ˆãã®è¦ä»¶ã‹ã‚‰ã‚µãƒãƒªãƒ¼å†ç”Ÿæˆï¼‰â†’æ—¢å­˜ï¼‹è¿½åŠ ãƒšãƒ«ã‚½ãƒŠâ†’å†ãƒ’ã‚¢ãƒªãƒ³ã‚°
        # æ”¹å–„ãƒãƒ¼ãƒ‰ã§ user_request ã¨ augment_personas ã‚’ã‚»ãƒƒãƒˆã—ã€ç›´æ¥ persona ç”Ÿæˆã¸æˆ»ã™
        workflow.add_edge("improve_requirements", "generate_personas")

        # æœ€çµ‚æˆæœç‰© â†’ END
        workflow.add_edge("generate_pitch", END)

        return workflow.compile()

    # --- ãƒãƒ¼ãƒ‰å®Ÿè£… ---
    def _clarification_interview_node(self, state: InterviewState):
        print("--- 1. åˆæœŸã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ ---")
        questions_str = self.clarification_interviewer.generate_questions(
            problem=state.initial_problem,
            persona=state.initial_persona,
            solution=state.initial_solution
        )
        print("\nã€AIãƒ¡ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ã®è³ªå•ã€‘\n" + questions_str)
        print("\nå›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (Enterã‚­ãƒ¼2å›ã§çµ‚äº†):")
        user_answers = []
        while True:
            try:
                line = input()
            except EOFError:
                line = ""
            if not line:
                break
            user_answers.append(line)
        answers_str = "\n".join(user_answers)
        log = f"## åˆæœŸãƒ’ã‚¢ãƒªãƒ³ã‚°\n\n### è³ªå•\n{questions_str}\n\n### å›ç­”\n{answers_str}"
        return {"clarification_interview_log": log}

    def _summarize_request_node(self, state: InterviewState):
        print("\n--- 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼ç”Ÿæˆ ---")
        summary = self.request_summarizer.run(
            problem=state.initial_problem,
            persona=state.initial_persona,
            solution=state.initial_solution,
            interview_log=state.clarification_interview_log
        )
        return {"user_request": summary}

    def _generate_personas_node(self, state: InterviewState):
        print("\n--- 3. ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆï¼ˆåˆ¶ç´„æº–æ‹ ï¼‹æ¡ç‚¹ï¼‰ ---")
        # æ”¹å–„ãƒ«ãƒ¼ãƒ—ä¸­ã¯æ—¢å­˜ã‚’ä¿æŒã—ã¤ã¤è¿½åŠ 
        constraints = self.constraint_extractor.run(
            problem=state.initial_problem,
            persona=state.initial_persona,
            solution=state.initial_solution,
            interview_log=state.clarification_interview_log
        )
        personas_result = self.persona_generator.run(
            user_request=state.user_request,
            constraints=constraints
        )
        if state.augment_personas and state.personas:
            merged = list(state.personas) + list(personas_result.personas[:max(1, min(3, len(personas_result.personas)))])
            return {
                "personas": merged,
                "iteration": 0,
                "is_information_sufficient": False,
                "augment_personas": False,  # ä½¿ã„åˆ‡ã‚Š
                "interviews": []  # å†ãƒ’ã‚¢ãƒªãƒ³ã‚°ã®ãŸã‚ä¸€æ—¦ã‚¯ãƒªã‚¢
            }
        else:
            return {"personas": personas_result.personas, "iteration": 0, "is_information_sufficient": False}

    def _conduct_interviews_node(self, state: InterviewState):
        print(f"\n--- 4. è©³ç´°ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å®Ÿæ–½ï¼ˆå„ãƒšãƒ«ã‚½ãƒŠ3å•ï¼‰ (ã‚µã‚¤ã‚¯ãƒ«: {state.iteration + 1}) ---")
        interviews_result = self.interview_conductor.run(user_request=state.user_request, personas=state.personas)
        return {"interviews": interviews_result.interviews}

    def _evaluate_information_node(self, state: InterviewState):
        print("\n--- 5. æƒ…å ±ã®ååˆ†æ€§ã‚’è©•ä¾¡ ---")
        evaluation_result = self.information_evaluator.run(user_request=state.user_request, interviews=state.interviews)
        print(f"è©•ä¾¡: {'ååˆ†' if evaluation_result.is_sufficient else 'ä¸ååˆ†'}")
        if not evaluation_result.is_sufficient:
            if evaluation_result.gaps:
                print("ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±:")
                for g in evaluation_result.gaps:
                    print(f"- {g}")
            if evaluation_result.followup_questions:
                print("æ¨å¥¨ã•ã‚Œã‚‹è¿½åŠ å…¥åŠ›è³ªå•ï¼ˆè¦ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ç­”ï¼‰:")
                for q in evaluation_result.followup_questions:
                    print(f"- {q}")
        return {
            "is_information_sufficient": evaluation_result.is_sufficient,
            "iteration": state.iteration + 1,
            "evaluation_result": evaluation_result
        }

    def _ask_followups_node(self, state: InterviewState):
        """ä¸è¶³ã«åŸºã¥ãè¿½åŠ å…¥åŠ›ï¼ˆ1å›ç›®è‡ªç”±ï¼2å›ç›®ã¯ã„ãƒ»ã„ã„ãˆï¼‰ï¼‹2å›ç›®å¾Œã¯è‡ªå‹•è£œå®Œã‚’å®Ÿæ–½"""
        round_num = state.followup_round
        mode = "free" if round_num == 0 else "yesno"
        collected = self.followup_asker.collect(state.evaluation_result, mode=mode) if state.evaluation_result else ""
        appended_log = state.clarification_interview_log

        if collected:
            appended_log += "\n\n" + collected

        # 2å›ç›®ãŒçµ‚ã‚ã£ãŸã‚‰ã€è‡ªå‹•è£œå®Œã§ä»®è¨­å®šã‚’è¿½è¨˜ã—ã¦å‰ã«é€²ã‚ã‚„ã™ãã™ã‚‹
        if round_num >= 1:
            auto_text = self.assumption_backfiller.run(
                user_request=state.user_request,
                interviews=state.interviews,
                gaps=state.evaluation_result.gaps if state.evaluation_result else []
            )
            appended_log += "\n\n## è‡ªå‹•è£œå®Œï¼ˆAIä»®è¨­å®šï¼‰\n" + auto_text

        return {"clarification_interview_log": appended_log, "followup_round": round_num + 1}

    def _generate_professional_requirements_node(self, state: InterviewState):
        print("\n--- 6. ã€çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼‰ã€‘ä½œæˆä¸­ ---")
        prof_reqs = self.professional_requirements_generator.run(user_request=state.user_request, interviews=state.interviews)
        return {"professional_requirements_doc": prof_reqs}

    def _analyze_environment_node(self, state: InterviewState):
        print("\n--- 7. ã€æˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã€‘å¤–éƒ¨ç’°å¢ƒã‚’åˆ†æä¸­ ---")
        report = self.consultant_analyzer.run(professional_requirements_doc=state.professional_requirements_doc)
        return {"consultant_analysis_report": report}

    # ====== åˆ†å‰²è©•ä¾¡ãƒãƒ¼ãƒ‰ ======
    def _assess_profitability_node(self, state: InterviewState):
        print("\n--- 8a. åç›Šæ€§è©•ä¾¡ ---")
        assessment = self.profitability_assessor.run(req=state.professional_requirements_doc, ext=state.consultant_analysis_report)
        print(f"åç›Šæ€§: {'OK' if assessment.is_profitable else 'NG'} / ç†ç”±: {assessment.reason[:80]}...")
        return {"profitability": assessment}

    def _assess_feasibility_node(self, state: InterviewState):
        print("\n--- 8b. å®Ÿç¾æ€§è©•ä¾¡ ---")
        assessment = self.feasibility_assessor.run(req=state.professional_requirements_doc, ext=state.consultant_analysis_report)
        print(f"å®Ÿç¾æ€§: {'OK' if assessment.is_feasible else 'NG'} / ç†ç”±: {assessment.reason[:80]}...")
        return {"feasibility": assessment}

    def _assess_legal_node(self, state: InterviewState):
        print("\n--- 8c. æ³•å‹™ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è©•ä¾¡ ---")
        assessment = self.legal_assessor.run(req=state.professional_requirements_doc, ext=state.consultant_analysis_report)
        print(f"æ³•å‹™: {'OK' if assessment.is_compliant else 'NG'} / ç†ç”±: {assessment.reason[:80]}...")
        return {"legal": assessment}

    def _assessment_gate_node(self, state: InterviewState):
        # ãƒ€ãƒŸãƒ¼ï¼ˆé·ç§»ã¯ _assessment_gate_branch ãŒæ±ºå®šï¼‰
        return {}

    def _improve_requirements_node(self, state: InterviewState):
        print("\n--- 9. æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼šè¦ä»¶å®šç¾©æ›¸ã‚’æ”¹è¨‚ä¸­ ---")
        bad_reasons: List[str] = []
        if state.profitability and not state.profitability.is_profitable:
            bad_reasons.append(f"[åç›Šæ€§NG] {state.profitability.reason}")
        if state.feasibility and not state.feasibility.is_feasible:
            bad_reasons.append(f"[å®Ÿç¾æ€§NG] {state.feasibility.reason}")
        if state.legal and not state.legal.is_compliant:
            bad_reasons.append(f"[æ³•å‹™NG] {state.legal.reason}")

        improved_doc = self.requirements_improver.run(
            req=state.professional_requirements_doc,
            ext=state.consultant_analysis_report,
            bad_reasons=bad_reasons
        )
        # æ”¹è¨‚ç‰ˆã‹ã‚‰æ–°ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        new_summary = self.summary_from_requirements.run(improved_doc)

        print("â†’ æ”¹è¨‚ç‰ˆè¦ä»¶å®šç¾©æ›¸ã‚’ã‚µãƒãƒªãƒ¼ã«åæ˜ ã€‚æ—¢å­˜ãƒšãƒ«ã‚½ãƒŠã‚’ä¿æŒã—ã¤ã¤ã€è¿½åŠ ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦å†ãƒ’ã‚¢ãƒªãƒ³ã‚°ã¸ã€‚")
        return {
            "professional_requirements_doc": improved_doc,
            "user_request": new_summary,
            "augment_personas": True,
            "interviews": [],  # å†ãƒ’ã‚¢ãƒªãƒ³ã‚°æº–å‚™ã¨ã—ã¦ã‚¯ãƒªã‚¢
        }

    def _generate_pitch_node(self, state: InterviewState):
        print("\n--- 10. ã€å­¦ç”Ÿãƒªãƒ¼ãƒ€ãƒ¼AIã€‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸ã‚’ä½œæˆä¸­ ---")
        pitch = PitchGenerator(ChatOpenAI(model="gpt-4o", temperature=0)).run(
            user_request=state.user_request, interviews=state.interviews
        )
        return {"pitch_document": pitch}

    # --- åˆ†å²é–¢æ•° ---
    def _after_evaluation_branch(self, state: InterviewState) -> str:
        """ååˆ†æ€§è©•ä¾¡çµæœã«å¿œã˜ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿”ã™
        - ååˆ†: ãã®ã¾ã¾å‰é€²
        - ä¸ååˆ†: 1å›ç›®=è‡ªç”±è¨˜è¿°ã§è¿½åŠ å…¥åŠ› / 2å›ç›®=ã¯ã„ãƒ»ã„ã„ãˆã§è¿½åŠ å…¥åŠ› / 3å›ç›®ä»¥é™=è‡ªå‹•è£œå®Œã—ã¦å‰é€²
        """
        if state.is_information_sufficient:
            return "enough"
        if state.followup_round < 2:
            return "need_followups"
        return "autofill_and_forward"

    def _assessment_gate_branch(self, state: InterviewState) -> str:
        ok = (
            state.profitability and state.profitability.is_profitable and
            state.feasibility and state.feasibility.is_feasible and
            state.legal and state.legal.is_compliant
        )
        return "all_true" if ok else "refine_loop"

    # å®Ÿè¡Œ
    def run(self, problem: str, persona: str, solution: str):
        inputs = {"initial_problem": problem, "initial_persona": persona, "initial_solution": solution}
        return self.app.invoke(inputs, config={"recursion_limit": 100})
    
    

# =========================
# 5. å®Ÿè¡Œéƒ¨åˆ†
# =========================
def main():
    parser = argparse.ArgumentParser(description="å¤šè§’çš„ã‚¢ã‚¤ãƒ‡ã‚¢è©•ä¾¡ï¼†ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆåˆ†å‰²è©•ä¾¡ï¼‹æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼‰")
    parser.add_argument("--problem", type=str, required=True, help="è§£æ±ºã—ãŸã„èª²é¡Œ")
    parser.add_argument("--persona", type=str, required=True, help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹ãƒšãƒ«ã‚½ãƒŠ")
    parser.add_argument("--solution", type=str, required=True, help="ææ¡ˆã™ã‚‹è§£æ±ºç­–")
    parser.add_argument("--k", type=int, default=5, help="è©³ç´°åˆ†æã§ç”Ÿæˆã™ã‚‹ãƒšãƒ«ã‚½ãƒŠã®æ•°")
    args = parser.parse_args()

    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        agent = RequirementsAgent(llm=llm, persona_k=args.k)
        final_state = agent.run(problem=args.problem, persona=args.persona, solution=args.solution)

        print("\n\n" + "="*80)
        print(" " * 30 + "æœ€çµ‚ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        print("="*80)

        # 1. çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼šãƒ“ã‚¸ãƒã‚¹ï¼‹é–‹ç™ºï¼‰
        print("\n\n" + "#" * 30 + " 1. ğŸ“ çµ±åˆè¦ä»¶å®šç¾©æ›¸ï¼ˆå€‹äººé–‹ç™ºå‘ã‘ï¼šãƒ“ã‚¸ãƒã‚¹ï¼‹é–‹ç™ºï¼‰ " + "#" * 30)
        print(final_state.get("professional_requirements_doc"))

        # 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸
        print("\n\n" + "#" * 30 + " 2. ğŸš€ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¼ç”»æ›¸ (å­¦ç”Ÿå‘ã‘) " + "#" * 30)
        print(final_state.get("pitch_document"))

        # 3. å¤–éƒ¨ç’°å¢ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼ˆæŠœç²‹è¡¨ç¤ºï¼‰
        print("\n\n" + "#" * 30 + " 3. ğŸ“Š å¤–éƒ¨ç’°å¢ƒåˆ†æãƒ¬ãƒãƒ¼ãƒˆ (è¦ç‚¹) " + "#" * 30)
        report = final_state.get("consultant_analysis_report")
        if report:
            print("\n## å¸‚å ´ãƒ»é¡§å®¢åˆ†æ\n" + report.customer_analysis)
            print("\n## ç«¶åˆåˆ†æ\n" + report.competitor_analysis)
            print("\n## è‡ªç¤¾åˆ†æ\n" + report.company_analysis)
            print("\n## PESTåˆ†æ\n" + report.pest_analysis)
            print("\n## è¦ç´„ã¨æˆ¦ç•¥çš„æè¨€\n" + report.summary_and_strategy)

        # 4. åˆ†å‰²è©•ä¾¡ï¼ˆæœ€çµ‚çŠ¶æ…‹ï¼‰
        print("\n\n" + "#" * 30 + " 4. âœ… åˆ†å‰²è©•ä¾¡ã®æœ€çµ‚çµæœ " + "#" * 30)
        if final_state.get("profitability"):
            p = final_state["profitability"]
            print(f"- åç›Šæ€§: {'OK' if p.is_profitable else 'NG'} | ç†ç”±: {p.reason}")
        if final_state.get("feasibility"):
            f = final_state["feasibility"]
            print(f"- å®Ÿç¾æ€§: {'OK' if f.is_feasible else 'NG'} | ç†ç”±: {f.reason}")
        if final_state.get("legal"):
            l = final_state["legal"]
            print(f"- æ³•å‹™: {'OK' if l.is_compliant else 'NG'} | ç†ç”±: {l.reason}")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
