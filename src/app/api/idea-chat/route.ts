import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = process.env.OPENAI_API_KEY ? new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
}) : null

export async function POST(request: NextRequest) {
  try {
    if (!openai) {
      return NextResponse.json(
        { error: 'OpenAI API key is not configured' },
        { status: 503 }
      )
    }

    const { messages, currentFrames, mode } = await request.json()

    if (mode === 'analyze_and_update') {
      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’åˆ†æã—ã¦3æ ã‚’æ›´æ–°ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
      const systemPrompt = `
ã‚ãªãŸã¯åç›Šæ€§ã‚’é‡è¦–ã™ã‚‹ãƒ“ã‚¸ãƒã‚¹ä¼ç”»ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®3ã¤ã®è¦ç´ ã‚’æœ€é©åŒ–ã™ã‚‹å½¹å‰²ãŒã‚ã‚Šã¾ã™ï¼š

1. **ãƒšãƒ«ã‚½ãƒŠ**: å…·ä½“çš„ã§åç›Šæ€§ã®é«˜ã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼
2. **èª²é¡Œ**: ãã®ãƒšãƒ«ã‚½ãƒŠãŒæŠ±ãˆã‚‹æ·±åˆ»ã§å¸‚å ´æ€§ã®ã‚ã‚‹èª²é¡Œ  
3. **ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹**: èª²é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã—ã€é«˜ã„åç›Šæ€§ã‚’æŒã¤ã‚µãƒ¼ãƒ“ã‚¹

ç¾åœ¨ã®çŠ¶æ…‹ï¼š
- ãƒšãƒ«ã‚½ãƒŠ: ${currentFrames.persona || 'æœªè¨­å®š'}
- èª²é¡Œ: ${currentFrames.problem || 'æœªè¨­å®š'}
- ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹: ${currentFrames.service || 'æœªè¨­å®š'}

## ã‚ãªãŸã®å½¹å‰²

1. **å…¥åŠ›å†…å®¹ã‚’åˆ†æ**ã—ã¦ã€ãƒšãƒ«ã‚½ãƒŠãƒ»èª²é¡Œãƒ»ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹ã®ã©ã®è¦ç´ ã«é–¢é€£ã™ã‚‹ã‹ã‚’åˆ¤æ–­
2. **æ—¢å­˜ã®3æ ã‚’æ”¹å–„**ã™ã‚‹ææ¡ˆã‚’è¡Œã†ï¼ˆå…¥åŠ›å†…å®¹ã‚’è¸ã¾ãˆã¦ã€ã‚ˆã‚Šåç›Šæ€§ã®é«˜ã„æ–¹å‘ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼‰
3. **ç›¸äº’é–¢é€£æ€§ã‚’è€ƒæ…®**ã—ã¦ã€ä¸€ã¤ã®è¦ç´ ãŒå¤‰ã‚ã£ãŸã‚‰ä»–ã®è¦ç´ ã‚‚æœ€é©åŒ–ã™ã‚‹
4. **å¸‚å ´æ€§ãƒ»åç›Šæ€§ãƒ»å®Ÿç¾å¯èƒ½æ€§**ã‚’é‡è¦–ã—ãŸæ”¹å–„æ¡ˆã‚’æç¤º

## å¿œç­”å½¢å¼

ã¾ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã«å¯¾ã™ã‚‹å…±æ„Ÿçš„ãªå¿œç­”ã‚’è¡Œã„ã€ãã®å¾Œã§æ”¹å–„ææ¡ˆãŒã‚ã‚Œã°ä»¥ä¸‹ã®JSONã‚’æœ€å¾Œã«å«ã‚ã¦ãã ã•ã„ï¼š

\`\`\`json
{
  "persona": "æ”¹å–„ã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠï¼ˆå¤‰æ›´ãŒãªã„å ´åˆã¯ nullï¼‰",
  "problem": "æ”¹å–„ã•ã‚ŒãŸèª²é¡Œï¼ˆå¤‰æ›´ãŒãªã„å ´åˆã¯ nullï¼‰", 
  "service": "æ”¹å–„ã•ã‚ŒãŸã‚µãƒ¼ãƒ“ã‚¹å†…å®¹ï¼ˆå¤‰æ›´ãŒãªã„å ´åˆã¯ nullï¼‰"
}
\`\`\`

æ”¹å–„ææ¡ˆãŒãªã„å ´åˆã¯ã€è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¦å¯¾è©±ã‚’æ·±ã‚ã¦ãã ã•ã„ã€‚
`

      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          { role: "system", content: systemPrompt },
          ...messages
        ],
        temperature: 0.8,
        max_tokens: 1200,
      })

      const response = completion.choices[0]?.message?.content || 'ã™ã¿ã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'
      
      // JSONã‚’æŠ½å‡ºã—ã¦updatesã¨ã—ã¦è¿”ã™
      let updates: { persona?: string; problem?: string; service?: string } | null = null
      const jsonMatch = response.match(/```json\n([\s\S]*?)\n```/)
      if (jsonMatch) {
        try {
          const parsedUpdates = JSON.parse(jsonMatch[1])
          // nullå€¤ã‚’é™¤å»
          const tempUpdates: { persona?: string; problem?: string; service?: string } = {}
          if (parsedUpdates.persona) tempUpdates.persona = parsedUpdates.persona
          if (parsedUpdates.problem) tempUpdates.problem = parsedUpdates.problem
          if (parsedUpdates.service) tempUpdates.service = parsedUpdates.service
          
          // ç©ºã®updatesã®å ´åˆã¯nullã«
          if (Object.keys(tempUpdates).length === 0) {
            updates = null
          } else {
            updates = tempUpdates
          }
        } catch (e) {
          console.error('JSON parsing error:', e)
        }
      }

      // JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
      const cleanResponse = response.replace(/```json\n[\s\S]*?\n```/g, '').trim()

      return NextResponse.json({ 
        response: cleanResponse,
        updates 
      })

    } else if (mode === 'generate_plan') {
      // ä¼ç”»æ›¸ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰
      const systemPrompt = `
ã‚ãªãŸã¯å®Ÿç¸¾è±Šå¯Œãªãƒ“ã‚¸ãƒã‚¹ä¼ç”»æ›¸ä½œæˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®3ã¤ã®è¦ç´ ã‹ã‚‰ã€åç›Šæ€§ã¨å®Ÿç¾å¯èƒ½æ€§ã‚’é‡è¦–ã—ãŸè©³ç´°ãªä¼ç”»æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®è¦ç´ ï¼š
- ãƒšãƒ«ã‚½ãƒŠ: ${currentFrames.persona}
- èª²é¡Œ: ${currentFrames.problem}  
- ã‚µãƒ¼ãƒ“ã‚¹å†…å®¹: ${currentFrames.service}

## ä¼ç”»æ›¸ä½œæˆã®æ–¹é‡

1. **åç›Šæ€§é‡è¦–**: æ˜ç¢ºãªåç›Šãƒ¢ãƒ‡ãƒ«ã¨å¸‚å ´æ€§ã‚’ç¤ºã™
2. **å®Ÿç¾å¯èƒ½æ€§**: æŠ€è¡“çš„ãƒ»äº‹æ¥­çš„ã«å®Ÿç¾å¯èƒ½ãªå†…å®¹
3. **å·®åˆ¥åŒ–**: ç«¶åˆã«å¯¾ã™ã‚‹æ˜ç¢ºãªå„ªä½æ€§
4. **æˆé•·æ€§**: å°†æ¥çš„ãªæ‹¡å¼µå¯èƒ½æ€§ã‚’ç¤ºã™
5. **å…·ä½“æ€§**: æ›–æ˜§ãªè¡¨ç¾ã‚’é¿ã‘ã€å…·ä½“çš„ãªæ•°å€¤ã‚„äº‹ä¾‹ã‚’å«ã‚€

## å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®å½¢å¼ã§ä¼ç”»æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

# ğŸš€ [ã‚µãƒ¼ãƒ“ã‚¹å]

## ğŸ“ ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦
[3-4è¡Œã§ç°¡æ½”ã«]

## ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒšãƒ«ã‚½ãƒŠ
[å…·ä½“çš„ãªäººç‰©åƒã¨å¸‚å ´è¦æ¨¡]

## âš¡ è§£æ±ºã™ã‚‹èª²é¡Œ
[èª²é¡Œã®æ·±åˆ»ã•ã¨å¸‚å ´æ€§]

## ğŸ’¡ ä¾¡å€¤ææ¡ˆãƒ»è§£æ±ºç­–
[ç‹¬è‡ªæ€§ã®ã‚ã‚‹è§£æ±ºæ–¹æ³•]

## ğŸ† ç«¶åˆåˆ†æãƒ»å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ
[3-5ã¤ã®ç«¶åˆã¨æ˜ç¢ºãªå·®åˆ¥åŒ–]

## ğŸ“Š å¸‚å ´è¦æ¨¡ãƒ»åç›Šæ€§
[TAM/SAM/åç›Šäºˆæ¸¬]

## ğŸª MVPï¼ˆæœ€å°å®Ÿç”¨ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆï¼‰
[æœ€åˆã«ãƒªãƒªãƒ¼ã‚¹ã™ã‚‹æ©Ÿèƒ½]

## ğŸ’° ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«
[ä¾¡æ ¼è¨­å®šãƒ»åç›Šæ§‹é€ ãƒ»ã‚³ã‚¹ãƒˆ]

## ğŸš€ å°†æ¥å±•é–‹ãƒ»æˆé•·æˆ¦ç•¥
[æ®µéšçš„ãªæ‹¡å¼µè¨ˆç”»]

## ğŸ“ˆ æˆåŠŸæŒ‡æ¨™ãƒ»KPI
[æ¸¬å®šå¯èƒ½ãªç›®æ¨™å€¤]

å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå†…å®¹ã‚’è¨˜è¼‰ã—ã€æŠ•è³‡å®¶ã‚„é–‹ç™ºãƒãƒ¼ãƒ ãŒç´å¾—ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®ä¼ç”»æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
`

      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          { role: "system", content: systemPrompt },
          ...messages.slice(-3) // æœ€æ–°ã®3ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ä½¿ç”¨
        ],
        temperature: 0.7,
        max_tokens: 3000,
      })

      const response = completion.choices[0]?.message?.content || 'ä¼ç”»æ›¸ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚'

      return NextResponse.json({ response })

    } else {
      return NextResponse.json(
        { error: 'Invalid mode specified' },
        { status: 400 }
      )
    }

  } catch (error) {
    console.error('OpenAI API error:', error)
    return NextResponse.json(
      { error: 'AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ' },
      { status: 500 }
    )
  }
}